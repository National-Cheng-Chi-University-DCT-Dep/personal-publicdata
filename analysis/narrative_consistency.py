#!/usr/bin/env python3
"""
Cross-Document Narrative Consistency Checker

Features:
- LLM-powered narrative analysis across CV, SOP, and recommendation materials
- Consistency scoring and conflict detection
- Story coherence validation
- Personalized improvement suggestions
- Multi-document semantic alignment analysis
"""

import os
import sys
import json
import yaml
import requests
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from dataclasses import dataclass
import re

@dataclass
class NarrativeElement:
    document_type: str  # CV, SOP, Recommendation
    content: str
    themes: List[str]
    keywords: List[str]
    tone: str
    emphasis: List[str]

@dataclass
class ConsistencyAnalysis:
    overall_score: float  # 0-100
    conflicts: List[Dict[str, Any]]
    strengths: List[str]
    suggestions: List[str]
    theme_alignment: Dict[str, float]
    narrative_coherence: float

class NarrativeConsistencyChecker:
    """Cross-document narrative consistency analysis system"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.source_data_dir = self.base_dir / "source_data"
        self.output_dir = self.base_dir / "final_applications"
        self.templates_dir = self.base_dir / "templates"
        
        # Load narrative configuration
        self.load_narrative_profile()
        self.setup_llm_integration()
    
    def load_narrative_profile(self):
        """Load user's core narrative themes and keywords"""
        profile_file = self.source_data_dir / "narrative_profile.yml"
        
        # Default narrative profile (will be created if not exists)
        default_profile = {
            'core_themes': [
                'æˆé•·æ›²ç·š',  # Growth trajectory
                'é›²ç«¯å®‰å…¨æ¶æ§‹',  # Cloud security architecture
                'é‡å­è¨ˆç®—æ½›åŠ›',  # Quantum computing potential
                'è·¨é ˜åŸŸæ•´åˆ',  # Cross-domain integration
                'å¯¦å‹™å°å‘å‰µæ–°'  # Practice-oriented innovation
            ],
            'narrative_strategy': 'technical_leader_with_research_vision',
            'key_experiences': [
                'Taiwan Stock Exchange cybersecurity consulting',
                'Twister5 team leadership',
                'Academic excellence transformation',
                'International perspective development'
            ],
            'target_image': 'experienced_practitioner_seeking_advanced_research',
            'avoid_contradictions': [
                'pure_academic_vs_industry_experience',
                'individual_vs_team_accomplishments',
                'technical_depth_vs_breadth_claims'
            ]
        }
        
        if profile_file.exists():
            with open(profile_file, 'r', encoding='utf-8') as f:
                self.narrative_profile = yaml.safe_load(f)
        else:
            # Create default profile
            self.narrative_profile = default_profile
            with open(profile_file, 'w', encoding='utf-8') as f:
                yaml.dump(default_profile, f, default_flow_style=False, allow_unicode=True)
            
            print(f"ğŸ“ Created default narrative profile: {profile_file}")
    
    def setup_llm_integration(self):
        """Setup LLM API integration"""
        # This is a placeholder for LLM integration
        # In production, you would use OpenAI API, Anthropic Claude, or other LLM services
        self.llm_available = False
        self.api_key = os.environ.get('OPENAI_API_KEY')
        
        if self.api_key:
            self.llm_available = True
            print("âœ… LLM integration ready")
        else:
            print("âš ï¸  LLM API key not found. Using rule-based analysis.")
    
    def extract_document_content(self, file_path: Path) -> str:
        """Extract content from document file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Remove markdown formatting for analysis
            content = re.sub(r'#+\s*', '', content)  # Headers
            content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)  # Bold
            content = re.sub(r'\*(.*?)\*', r'\1', content)  # Italic
            content = re.sub(r'\[.*?\]\(.*?\)', '', content)  # Links
            content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)  # Code blocks
            
            return content.strip()
        except Exception as e:
            print(f"âš ï¸  Could not read {file_path}: {e}")
            return ""
    
    def analyze_document_themes(self, content: str, doc_type: str) -> NarrativeElement:
        """Analyze themes and emphasis in a document"""
        # Extract key themes based on content analysis
        themes = []
        keywords = []
        emphasis = []
        
        # Theme detection based on keywords
        theme_keywords = {
            'æˆé•·æ›²ç·š': ['growth', 'improvement', 'development', 'progression', 'advancement', 'evolution', 'learning'],
            'é›²ç«¯å®‰å…¨æ¶æ§‹': ['cloud', 'security', 'architecture', 'infrastructure', 'AWS', 'cybersecurity', 'defense'],
            'é‡å­è¨ˆç®—æ½›åŠ›': ['quantum', 'computing', 'cryptography', 'post-quantum', 'algorithm', 'qiskit'],
            'è·¨é ˜åŸŸæ•´åˆ': ['interdisciplinary', 'integration', 'collaboration', 'cross-functional', 'diverse'],
            'å¯¦å‹™å°å‘å‰µæ–°': ['practical', 'implementation', 'real-world', 'industry', 'application', 'solution']
        }
        
        content_lower = content.lower()
        
        for theme, theme_words in theme_keywords.items():
            if any(word in content_lower for word in theme_words):
                themes.append(theme)
                # Count frequency for emphasis
                frequency = sum(content_lower.count(word) for word in theme_words)
                if frequency >= 3:
                    emphasis.append(theme)
        
        # Extract key technical keywords
        tech_keywords = [
            'python', 'cybersecurity', 'machine learning', 'ai', 'cloud', 'security',
            'quantum', 'cryptography', 'blockchain', 'devops', 'automation',
            'leadership', 'management', 'consulting', 'architecture', 'engineering'
        ]
        
        for keyword in tech_keywords:
            if keyword in content_lower:
                keywords.append(keyword)
        
        # Analyze tone (simplified)
        formal_indicators = ['furthermore', 'therefore', 'consequently', 'moreover', 'research', 'academic']
        personal_indicators = ['i', 'my', 'personally', 'believe', 'passion', 'excited', 'dream']
        
        formal_count = sum(content_lower.count(word) for word in formal_indicators)
        personal_count = sum(content_lower.count(word) for word in personal_indicators)
        
        if formal_count > personal_count:
            tone = "formal_academic"
        elif personal_count > formal_count:
            tone = "personal_narrative"
        else:
            tone = "balanced"
        
        return NarrativeElement(
            document_type=doc_type,
            content=content[:500],  # First 500 chars for analysis
            themes=themes,
            keywords=keywords,
            tone=tone,
            emphasis=emphasis
        )
    
    def call_llm_api(self, prompt: str) -> Optional[str]:
        """Call LLM API for advanced analysis"""
        if not self.llm_available:
            return None
        
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'You are an expert admissions consultant analyzing university application documents for narrative consistency and coherence.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 1000,
                'temperature': 0.3
            }
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                print(f"âš ï¸  LLM API error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âš ï¸  LLM API call failed: {e}")
            return None
    
    def analyze_cross_document_consistency(self, documents: List[NarrativeElement]) -> ConsistencyAnalysis:
        """Analyze consistency across multiple documents"""
        conflicts = []
        strengths = []
        suggestions = []
        theme_alignment = {}
        
        # Analyze theme consistency
        all_themes = set()
        for doc in documents:
            all_themes.update(doc.themes)
        
        for theme in all_themes:
            docs_with_theme = [doc for doc in documents if theme in doc.themes]
            emphasis_docs = [doc for doc in documents if theme in doc.emphasis]
            
            alignment_score = len(docs_with_theme) / len(documents)
            theme_alignment[theme] = alignment_score
            
            if alignment_score >= 0.8:
                strengths.append(f"å¼·åŠ›ä¸»é¡Œä¸€è‡´æ€§: '{theme}' åœ¨å¤šæ•¸æ–‡ä»¶ä¸­éƒ½æœ‰é«”ç¾")
            elif alignment_score <= 0.3:
                conflicts.append({
                    'type': 'theme_inconsistency',
                    'severity': 'medium',
                    'description': f"ä¸»é¡Œ '{theme}' åªåœ¨éƒ¨åˆ†æ–‡ä»¶ä¸­å‡ºç¾ï¼Œå¯èƒ½é€ æˆæ•˜äº‹ä¸ä¸€è‡´",
                    'affected_documents': [doc.document_type for doc in docs_with_theme],
                    'suggestion': f"è€ƒæ…®åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­æ›´å‡å‹»åœ°é«”ç¾ '{theme}' ä¸»é¡Œ"
                })
        
        # Analyze tone consistency
        tones = [doc.tone for doc in documents]
        if len(set(tones)) > 2:
            conflicts.append({
                'type': 'tone_inconsistency',
                'severity': 'high',
                'description': 'æ–‡ä»¶é–“èªèª¿å·®ç•°éå¤§ï¼Œå¯èƒ½å½±éŸ¿æ•´é«”å½¢è±¡ä¸€è‡´æ€§',
                'affected_documents': [f"{doc.document_type}({doc.tone})" for doc in documents],
                'suggestion': 'çµ±ä¸€æ‰€æœ‰æ–‡ä»¶çš„èªèª¿é¢¨æ ¼ï¼Œå»ºè­°ä½¿ç”¨å¹³è¡¡çš„å­¸è¡“-å€‹äººæ•˜äº‹é¢¨æ ¼'
            })
        
        # Analyze keyword overlap
        all_keywords = []
        for doc in documents:
            all_keywords.extend(doc.keywords)
        
        keyword_frequency = {}
        for keyword in all_keywords:
            keyword_frequency[keyword] = all_keywords.count(keyword)
        
        # Check for missing core keywords across documents
        core_keywords = ['cybersecurity', 'security', 'quantum', 'leadership', 'research']
        missing_keywords = []
        
        for keyword in core_keywords:
            if keyword_frequency.get(keyword, 0) < len(documents) * 0.5:
                missing_keywords.append(keyword)
        
        if missing_keywords:
            suggestions.append(f"è€ƒæ…®åœ¨æ›´å¤šæ–‡ä»¶ä¸­åŠ å…¥æ ¸å¿ƒé—œéµå­—: {', '.join(missing_keywords)}")
        
        # Analyze emphasis alignment with strategy
        target_strategy = self.narrative_profile.get('narrative_strategy', '')
        if 'technical_leader' in target_strategy:
            leadership_mentions = sum(1 for doc in documents if 'leadership' in doc.keywords)
            if leadership_mentions < len(documents) * 0.6:
                suggestions.append("ä½œç‚ºæŠ€è¡“é ˜å°è€…çš„å®šä½éœ€è¦åœ¨æ›´å¤šæ–‡ä»¶ä¸­é«”ç¾é ˜å°ç¶“é©—")
        
        # Calculate overall consistency score
        consistency_factors = [
            len(conflicts) == 0,  # No conflicts
            sum(theme_alignment.values()) / len(theme_alignment) if theme_alignment else 0.5,  # Theme alignment
            len(set(tones)) <= 2,  # Tone consistency
            len(missing_keywords) <= 1  # Keyword coverage
        ]
        
        narrative_coherence = sum(consistency_factors) / len(consistency_factors) * 100
        
        # Generate LLM-powered analysis if available
        if self.llm_available:
            llm_analysis = self.get_llm_narrative_analysis(documents)
            if llm_analysis:
                suggestions.extend(llm_analysis.get('suggestions', []))
        
        return ConsistencyAnalysis(
            overall_score=narrative_coherence,
            conflicts=conflicts,
            strengths=strengths,
            suggestions=suggestions,
            theme_alignment=theme_alignment,
            narrative_coherence=narrative_coherence
        )
    
    def get_llm_narrative_analysis(self, documents: List[NarrativeElement]) -> Optional[Dict]:
        """Get advanced LLM-powered narrative analysis"""
        if not self.llm_available:
            return None
        
        # Prepare document summaries for LLM
        doc_summaries = []
        for doc in documents:
            doc_summaries.append(f"{doc.document_type}: {doc.content[:200]}...")
        
        prompt = f"""
        Analyze the narrative consistency across these university application documents for a cybersecurity professional applying to graduate programs:

        CORE NARRATIVE THEMES: {', '.join(self.narrative_profile['core_themes'])}
        TARGET IMAGE: {self.narrative_profile.get('target_image', '')}

        DOCUMENTS:
        {chr(10).join(doc_summaries)}

        Please provide analysis in this JSON format:
        {{
            "consistency_score": (0-100),
            "narrative_strengths": ["strength1", "strength2"],
            "potential_conflicts": ["conflict1", "conflict2"],
            "suggestions": ["suggestion1", "suggestion2"],
            "overall_impression": "brief summary"
        }}
        """
        
        llm_response = self.call_llm_api(prompt)
        
        if llm_response:
            try:
                # Try to parse JSON response
                import json
                return json.loads(llm_response)
            except:
                # If JSON parsing fails, extract insights manually
                return {
                    'suggestions': [
                        'å»ºè­°ä½¿ç”¨LLM APIé€²è¡Œæ›´æ·±åº¦çš„èªæ„åˆ†æ',
                        'è€ƒæ…®å°ˆæ¥­ç”³è«‹é¡§å•çš„äººå·¥å¯©æŸ¥'
                    ]
                }
        
        return None
    
    def find_application_documents(self) -> List[Tuple[str, Path]]:
        """Find all application documents for analysis"""
        documents = []
        
        # Look for CV files
        cv_files = list(self.output_dir.rglob("CV_*.md"))
        if cv_files:
            documents.append(("CV", cv_files[0]))  # Use first CV file
        
        # Look for SOP files
        sop_files = list(self.output_dir.rglob("SOP_*.md"))
        if sop_files:
            documents.append(("SOP", sop_files[0]))  # Use first SOP file
        
        # Look for recommendation brag sheet (if exists)
        brag_sheet_files = list(self.templates_dir.glob("*brag*sheet*.md"))
        if brag_sheet_files:
            documents.append(("Recommendation", brag_sheet_files[0]))
        
        # Also check templates
        cv_template = self.templates_dir / "cv_template.md"
        if cv_template.exists() and ("CV", cv_template) not in documents:
            documents.append(("CV_Template", cv_template))
        
        sop_template = self.templates_dir / "sop_master_template.md"
        if sop_template.exists():
            documents.append(("SOP_Template", sop_template))
        
        return documents
    
    def run_consistency_analysis(self) -> Dict[str, Any]:
        """Run complete narrative consistency analysis"""
        print("ğŸ“– Running cross-document narrative consistency analysis...")
        
        # Find documents to analyze
        document_files = self.find_application_documents()
        
        if not document_files:
            print("âš ï¸  No application documents found for analysis")
            return {
                'error': 'No documents found',
                'suggestion': 'Run document generation first: .\intelligence.ps1 docs'
            }
        
        # Analyze each document
        analyzed_documents = []
        for doc_type, file_path in document_files:
            print(f"ğŸ“„ Analyzing {doc_type}: {file_path.name}")
            
            content = self.extract_document_content(file_path)
            if content:
                narrative_element = self.analyze_document_themes(content, doc_type)
                analyzed_documents.append(narrative_element)
        
        if not analyzed_documents:
            print("âŒ No valid documents could be analyzed")
            return {'error': 'Document analysis failed'}
        
        # Perform consistency analysis
        consistency_analysis = self.analyze_cross_document_consistency(analyzed_documents)
        
        # Generate report
        report_content = self.generate_consistency_report(consistency_analysis, analyzed_documents)
        
        # Save report
        report_file = self.output_dir / "narrative_consistency_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ Narrative consistency report saved to {report_file}")
        
        # Return summary
        return {
            'overall_score': consistency_analysis.overall_score,
            'documents_analyzed': len(analyzed_documents),
            'conflicts_found': len(consistency_analysis.conflicts),
            'suggestions_provided': len(consistency_analysis.suggestions),
            'theme_alignment_avg': sum(consistency_analysis.theme_alignment.values()) / len(consistency_analysis.theme_alignment) if consistency_analysis.theme_alignment else 0,
            'report_file': str(report_file)
        }
    
    def generate_consistency_report(self, analysis: ConsistencyAnalysis, documents: List[NarrativeElement]) -> str:
        """Generate comprehensive narrative consistency report"""
        report_lines = [
            "# ğŸ“– ç”³è«‹æ•˜äº‹ä¸€è‡´æ€§åˆ†æå ±å‘Š",
            "",
            f"**åˆ†ææ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**åˆ†ææ–‡ä»¶æ•¸**: {len(documents)}",
            f"**æ•´é«”ä¸€è‡´æ€§åˆ†æ•¸**: {analysis.overall_score:.1f}/100",
            ""
        ]
        
        # Overall assessment
        if analysis.overall_score >= 80:
            assessment = "ğŸŒŸ å„ªç§€ - æ‚¨çš„ç”³è«‹æ•˜äº‹é«˜åº¦ä¸€è‡´ä¸”é€£è²«"
            color = "success"
        elif analysis.overall_score >= 60:
            assessment = "âœ… è‰¯å¥½ - ç”³è«‹æ•˜äº‹åŸºæœ¬ä¸€è‡´ï¼Œæœ‰å°å¹…æ”¹é€²ç©ºé–“"
            color = "warning"
        else:
            assessment = "âš ï¸ éœ€æ”¹é€² - ç”³è«‹æ•˜äº‹å­˜åœ¨ä¸ä¸€è‡´ä¹‹è™•ï¼Œå»ºè­°é‡æ–°å¯©è¦–"
            color = "danger"
        
        report_lines.extend([
            "## ğŸ“Š ç¸½é«”è©•ä¼°",
            "",
            f"**{assessment}**",
            ""
        ])
        
        # Documents analyzed
        report_lines.extend([
            "## ğŸ“„ åˆ†ææ–‡ä»¶",
            "",
            "| æ–‡ä»¶é¡å‹ | ä¸»è¦ä¸»é¡Œ | èªèª¿é¢¨æ ¼ | é—œéµå­—æ•¸é‡ |",
            "|----------|----------|----------|------------|"
        ])
        
        for doc in documents:
            themes_str = ", ".join(doc.themes[:3]) if doc.themes else "ç„¡æ˜ç¢ºä¸»é¡Œ"
            report_lines.append(
                f"| {doc.document_type} | {themes_str} | {doc.tone} | {len(doc.keywords)} |"
            )
        
        report_lines.append("")
        
        # Theme alignment analysis
        if analysis.theme_alignment:
            report_lines.extend([
                "## ğŸ¯ ä¸»é¡Œä¸€è‡´æ€§åˆ†æ",
                "",
                "| æ ¸å¿ƒä¸»é¡Œ | è¦†è“‹ç‡ | è©•ä¼° |",
                "|----------|---------|------|"
            ])
            
            for theme, alignment in analysis.theme_alignment.items():
                if alignment >= 0.8:
                    assessment = "âœ… å„ªç§€"
                elif alignment >= 0.5:
                    assessment = "âš ï¸ ä¸­ç­‰"
                else:
                    assessment = "âŒ ä¸è¶³"
                
                report_lines.append(f"| {theme} | {alignment:.1%} | {assessment} |")
            
            report_lines.append("")
        
        # Strengths
        if analysis.strengths:
            report_lines.extend([
                "## âœ… æ•˜äº‹å„ªå‹¢",
                ""
            ])
            
            for strength in analysis.strengths:
                report_lines.append(f"- {strength}")
            
            report_lines.append("")
        
        # Conflicts and issues
        if analysis.conflicts:
            report_lines.extend([
                "## âš ï¸ ç™¼ç¾çš„å•é¡Œ",
                ""
            ])
            
            for conflict in analysis.conflicts:
                severity_icon = {
                    'high': 'ğŸš¨',
                    'medium': 'âš ï¸',
                    'low': 'ğŸ’¡'
                }
                
                icon = severity_icon.get(conflict.get('severity', 'medium'), 'âš ï¸')
                report_lines.extend([
                    f"### {icon} {conflict.get('type', 'Unknown').replace('_', ' ').title()}",
                    "",
                    f"**å•é¡Œæè¿°**: {conflict.get('description', 'N/A')}",
                    f"**å½±éŸ¿æ–‡ä»¶**: {', '.join(conflict.get('affected_documents', []))}",
                    f"**å»ºè­°è™•ç†**: {conflict.get('suggestion', 'N/A')}",
                    ""
                ])
        
        # Suggestions for improvement
        if analysis.suggestions:
            report_lines.extend([
                "## ğŸ’¡ æ”¹é€²å»ºè­°",
                ""
            ])
            
            for i, suggestion in enumerate(analysis.suggestions, 1):
                report_lines.append(f"{i}. {suggestion}")
            
            report_lines.append("")
        
        # Core narrative profile
        report_lines.extend([
            "## ğŸ­ æ ¸å¿ƒæ•˜äº‹ç­–ç•¥",
            "",
            f"**ç›®æ¨™å½¢è±¡**: {self.narrative_profile.get('target_image', 'N/A')}",
            f"**æ•˜äº‹ç­–ç•¥**: {self.narrative_profile.get('narrative_strategy', 'N/A')}",
            "",
            "**æ ¸å¿ƒä¸»é¡Œ**:",
        ])
        
        for theme in self.narrative_profile.get('core_themes', []):
            alignment_score = analysis.theme_alignment.get(theme, 0)
            status_icon = "âœ…" if alignment_score >= 0.7 else "âš ï¸" if alignment_score >= 0.4 else "âŒ"
            report_lines.append(f"- {status_icon} {theme} ({alignment_score:.1%} è¦†è“‹ç‡)")
        
        # Action items
        report_lines.extend([
            "",
            "## ğŸ¯ è¡Œå‹•è¨ˆç•«",
            ""
        ])
        
        if analysis.overall_score >= 80:
            report_lines.extend([
                "æ‚¨çš„ç”³è«‹æ•˜äº‹å·²ç¶“ç›¸ç•¶å„ªç§€ï¼å»ºè­°ï¼š",
                "1. é€²è¡Œæœ€çµ‚æ ¡å°ï¼Œç¢ºä¿ç´°ç¯€å®Œç¾",
                "2. è«‹å°ˆæ¥­é¡§å•æˆ–è³‡æ·±ç”³è«‹è€…é€²è¡ŒåŒå„•è©•è­°",
                "3. é‡å°ä¸åŒå­¸æ ¡é€²è¡Œå¾®èª¿å„ªåŒ–"
            ])
        else:
            report_lines.extend([
                "å»ºè­°æŒ‰ä»¥ä¸‹å„ªå…ˆç´šæ”¹é€²ç”³è«‹æ•˜äº‹ï¼š",
                "1. **é«˜å„ªå…ˆç´š**: è§£æ±ºä¸Šè¿°æ¨™è¨˜çš„è¡çªå•é¡Œ",
                "2. **ä¸­å„ªå…ˆç´š**: å¯¦æ–½æ”¹é€²å»ºè­°ä¸­çš„å‰3é …",
                "3. **ä½å„ªå…ˆç´š**: å¢å¼·ä¸»é¡Œä¸€è‡´æ€§è¦†è“‹ç‡",
                "4. **æŒçºŒ**: å®šæœŸé‡æ–°åˆ†æä¸¦å„ªåŒ–"
            ])
        
        report_lines.extend([
            "",
            "---",
            "",
            "## ğŸ“ é€²éšæ”¯æ´",
            "",
            "å¦‚éœ€æ›´æ·±åº¦çš„æ•˜äº‹åˆ†æï¼Œå»ºè­°ï¼š",
            "- ğŸ¤– é…ç½®LLM APIé€²è¡Œèªæ„å±¤é¢åˆ†æ",
            "- ğŸ‘¥ å°‹æ±‚å°ˆæ¥­ç”³è«‹é¡§å•æ„è¦‹",
            "- ğŸ“š åƒè€ƒæˆåŠŸç”³è«‹æ¡ˆä¾‹é€²è¡Œå°æ¯”",
            "",
            f"*å ±å‘Šç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} by Narrative Consistency Checker v2.0*"
        ])
        
        return "\n".join(report_lines)

def main():
    """Main narrative consistency analysis execution"""
    checker = NarrativeConsistencyChecker()
    
    try:
        # Run consistency analysis
        result = checker.run_consistency_analysis()
        
        if 'error' in result:
            print(f"âŒ Analysis failed: {result['error']}")
            if 'suggestion' in result:
                print(f"ğŸ’¡ {result['suggestion']}")
            return 1
        
        # Print summary
        print(f"\nğŸ“– Narrative Consistency Analysis Summary:")
        print(f"   Overall Score: {result['overall_score']:.1f}/100")
        print(f"   Documents Analyzed: {result['documents_analyzed']}")
        print(f"   Conflicts Found: {result['conflicts_found']}")
        print(f"   Suggestions Provided: {result['suggestions_provided']}")
        print(f"   Theme Alignment: {result['theme_alignment_avg']:.1%}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Narrative consistency analysis failed: {str(e)}")
        return 1

if __name__ == "__main__":
    sys.exit(main())

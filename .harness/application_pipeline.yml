pipeline:
  name: University Application Intelligence System v2.0 - Harness
  identifier: university_application_intelligence
  projectIdentifier: personal_publicdata
  orgIdentifier: default
  tags: 
    system: "application-intelligence"
    version: "2.0.0"
  
  properties:
    ci:
      codebase:
        connectorRef: github_connector
        repoName: personal-publicdata
        build: <+input>

  stages:
    - stage:
        name: Environment Setup and Dependencies
        identifier: setup
        description: Setup Python environment and install dependencies
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: System Information
                  identifier: system_info
                  spec:
                    shell: Bash
                    command: |
                      echo "🔧 System Setup - Application Intelligence System v2.0"
                      echo "Date: $(date)"
                      echo "Python version: $(python3 --version)"
                      echo "Pip version: $(pip3 --version)"
                      echo "Git commit: $(git rev-parse --short HEAD)"
                      
              - step:
                  type: Run
                  name: Install Dependencies
                  identifier: install_deps
                  spec:
                    shell: Bash
                    command: |
                      echo "📦 Installing Python dependencies..."
                      cd build_scripts
                      
                      # Install core dependencies
                      pip3 install --upgrade pip
                      pip3 install PyYAML requests beautifulsoup4 selenium
                      pip3 install pandas matplotlib seaborn
                      pip3 install nltk textblob scikit-learn
                      pip3 install python-dateutil pytz
                      pip3 install PyGithub
                      pip3 install rich structlog
                      pip3 install tqdm click
                      pip3 install jsonschema
                      pip3 install GitPython
                      
                      echo "✅ Core dependencies installed"
                      
                      # Try to install optional dependencies
                      echo "📦 Installing optional dependencies..."
                      pip3 install selenium webdriver-manager || echo "⚠️ Selenium dependencies failed"
                      pip3 install lxml html5lib || echo "⚠️ HTML parsing libraries failed"
                      pip3 install pillow opencv-python || echo "⚠️ Image processing libraries failed"
                      pip3 install markdown || echo "⚠️ Markdown processing failed"
                      
                      echo "📋 Installed packages:"
                      pip3 list | grep -E "(PyYAML|requests|beautifulsoup4|pandas|nltk|PyGithub)"

    - stage:
        name: Data Collection and Validation
        identifier: data_pipeline
        description: Automated data collection and validation
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Validate Configuration
                  identifier: validate_config
                  spec:
                    shell: Bash
                    command: |
                      echo "🔍 Validating system configuration..."
                      
                      # Check if required files exist
                      if [ ! -f "source_data/schools.yml" ]; then
                        echo "❌ schools.yml not found"
                        exit 1
                      fi
                      
                      # Validate YAML syntax
                      python3 -c "import yaml; yaml.safe_load(open('source_data/schools.yml'))"
                      echo "✅ schools.yml is valid"
                      
                      if [ -f "source_data/recommenders.yml" ]; then
                        python3 -c "import yaml; yaml.safe_load(open('source_data/recommenders.yml'))"
                        echo "✅ recommenders.yml is valid"
                      fi
                      
                      # List available schools
                      echo "📋 Available schools:"
                      cd build_scripts
                      python3 generate_docs.py --list
                      
              - step:
                  type: Run
                  name: Data Collection - Web Scraping
                  identifier: data_collection
                  spec:
                    shell: Bash
                    command: |
                      echo "🔍 Starting automated data collection..."
                      
                      # Set up environment variables for web scraping
                      export DISPLAY=:99
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)"
                      
                      # Run data collection with error handling
                      cd data_collection
                      
                      echo "🕷️ Running university data scraper..."
                      timeout 300 python3 scraper.py || {
                        echo "⚠️ Scraper timeout or error, continuing with existing data..."
                      }
                      
                      # Check if live data was created
                      if [ -f "../source_data/schools_live_data.yml" ]; then
                        echo "✅ Live data collection successful"
                        echo "📊 Live data summary:"
                        python3 -c "
                        import yaml
                        with open('../source_data/schools_live_data.yml') as f:
                            data = yaml.safe_load(f)
                            schools = data.get('schools_live_data', [])
                            print(f'Collected data for {len(schools)} schools')
                            for school in schools[:3]:
                                conf = school.get('confidence_score', 0)
                                print(f'  {school[\"school_id\"]}: {conf:.1%} confidence')
                        "
                      else
                        echo "⚠️ No live data collected, using static configuration"
                      fi
                      
              - step:
                  type: Run
                  name: Data Validation and Eligibility Check
                  identifier: validation
                  spec:
                    shell: Bash
                    command: |
                      echo "✅ Starting comprehensive data validation..."
                      
                      cd data_collection
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      echo "🔍 Running application eligibility validator..."
                      python3 validator.py
                      
                      # Check validation results
                      if [ -f "../final_applications/validation_report.md" ]; then
                        echo "✅ Validation completed successfully"
                        echo "📊 Validation summary:"
                        
                        # Use the safe validation summary script to avoid indentation errors
                        python3 validation_summary.py
                      else
                        echo "❌ Validation failed"
                        exit 1
                      fi

    - stage:
        name: Intelligence and Analysis
        identifier: intelligence
        description: Academic intelligence and opportunity analysis
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Academic Intelligence Gathering
                  identifier: academic_radar
                  spec:
                    shell: Bash
                    command: |
                      echo "🔬 Starting academic intelligence gathering..."
                      
                      cd analysis
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      # Run academic radar with timeout
                      echo "🎯 Analyzing research opportunities and professor networks..."
                      timeout 180 python3 academic_radar.py || {
                        echo "⚠️ Academic radar timeout, continuing with basic analysis..."
                      }
                      
                      # Check results
                      if [ -f "../final_applications/academic_intelligence_report.md" ]; then
                        echo "✅ Academic intelligence completed"
                        
                        # Use the safe academic summary script to avoid indentation errors
                        python3 ../data_collection/academic_summary.py
                      else
                        echo "⚠️ Academic intelligence not completed, continuing..."
                      fi
              
              - step:
                  type: Run
                  name: Generate Monitoring Dashboard
                  identifier: dashboard
                  spec:
                    shell: Bash
                    command: |
                      echo "📊 Generating application monitoring dashboard..."
                      
                      cd monitoring
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      python3 dashboard.py
                      
                      if [ -f "../final_applications/application_dashboard.md" ]; then
                        echo "✅ Dashboard generation successful"
                        
                        # Show dashboard summary
                        head -20 ../final_applications/application_dashboard.md
                      else
                        echo "❌ Dashboard generation failed"
                        exit 1
                      fi

    - stage:
        name: Document Generation
        identifier: document_generation
        description: Generate customized application documents
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Generate Application Documents
                  identifier: generate_docs
                  spec:
                    shell: Bash
                    command: |
                      echo "📝 Generating customized application documents..."
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      # Determine which schools to generate based on validation results
                      echo "📋 Determining priority schools for document generation..."
                      
                      if [ -f "../final_applications/validation_results.json" ]; then
                        # Extract eligible and warning schools using safe methods
                        echo "Priority schools for document generation:"
                        
                        # Create a simple Python script to avoid indentation issues
                        python3 -c "
                        import json
                        import sys
                        
                        try:
                            with open('../final_applications/validation_results.json') as f:
                                data = json.load(f)
                                results = data.get('results', {})
                                
                            priority_schools = [
                                school_id for school_id, result in results.items()
                                if result.get('overall_status') in ['ELIGIBLE', 'WARNING']
                            ]
                            
                            print('Priority schools for document generation:')
                            for school in priority_schools:
                                print(f'  - {school}')
                                
                            with open('priority_schools.txt', 'w') as f:
                                f.write(' '.join(priority_schools))
                                
                        except Exception as e:
                            print(f'Using all active schools: {e}')
                            with open('priority_schools.txt', 'w') as f:
                                f.write('all')
                        "
                      else
                        echo "Validation results not found, using all active schools"
                        echo "all" > priority_schools.txt
                      fi
                      
                      # Generate documents
                      if [ -f "priority_schools.txt" ]; then
                        SCHOOLS=$(cat priority_schools.txt)
                        if [ "$SCHOOLS" = "all" ]; then
                          echo "📝 Generating documents for all active schools..."
                          python3 generate_docs.py --all
                        else
                          echo "📝 Generating documents for priority schools..."
                          for school in $SCHOOLS; do
                            echo "  Generating for $school..."
                            python3 generate_docs.py --school "$school"
                          done
                        fi
                      else
                        echo "📝 Generating documents for all active schools..."
                        python3 generate_docs.py --all
                      fi
                      
                      # Document generation summary
                      echo "📊 Document Generation Summary:"
                      find ../final_applications -name "*.md" -path "*/CV_*" | wc -l | xargs echo "  CV documents generated:"
                      find ../final_applications -name "*.md" -path "*/SOP_*" | wc -l | xargs echo "  SOP documents generated:"

    - stage:
        name: Notifications and Task Management
        identifier: notifications
        description: Process alerts and create GitHub issues
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Process Alerts and Notifications
                  identifier: alerts
                  spec:
                    shell: Bash
                    command: |
                      echo "🔔 Processing alerts and notifications..."
                      
                      cd notifications
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      # Set GitHub token if available
                      if [ -n "$GITHUB_TOKEN" ]; then
                        export GITHUB_TOKEN="$GITHUB_TOKEN"
                        echo "✅ GitHub token configured for issue creation"
                      else
                        echo "⚠️ No GitHub token - issues will be logged but not created"
                      fi
                      
                      # Run notification system
                      python3 alert_system.py
                      
                      # Check results
                      if [ -f "../final_applications/alert_summary.json" ]; then
                        echo "✅ Alert processing completed"
                        
                        # Use the safe alert summary script to avoid indentation errors
                        python3 ../data_collection/alert_summary.py
                      else
                        echo "⚠️ Alert processing completed with no summary"
                      fi
                      
              - step:
                  type: Run
                  name: Master Controller Summary
                  identifier: master_summary
                  spec:
                    shell: Bash
                    command: |
                      echo "🎯 Running master controller for final summary..."
                      
                      # Ensure required dependencies are available
                      echo "📦 Checking and installing required dependencies..."
                      pip3 install --quiet beautifulsoup4 selenium requests PyYAML || echo "⚠️ Some dependencies may have failed to install"
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      # Run master controller in report mode
                      echo "📋 Generating comprehensive execution report..."
                      python3 master_controller.py --save-report --quick
                      
                      if [ -f "../final_applications/execution_report.md" ]; then
                        echo "✅ Master execution report generated"
                        
                        echo "📊 Final System Status:"
                        echo "========================================"
                        
                        # Show key sections of the execution report
                        grep -A 10 "## 📊 Pipeline Results" ../final_applications/execution_report.md || echo "Report sections not found"
                        
                        echo ""
                        echo "📁 Generated Files:"
                        ls -la ../final_applications/*.md ../final_applications/*.json 2>/dev/null || echo "No files generated"
                        
                      else
                        echo "⚠️ Master execution report not generated"
                      fi

    - stage:
        name: Advanced Intelligence Features
        identifier: advanced_features
        description: Run advanced AI-powered analysis features
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Gamification System
                  identifier: gamification
                  spec:
                    shell: Bash
                    command: |
                      echo "🎮 Running gamification system..."
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      echo "🏆 Updating achievements and progress tracking..."
                      python3 advanced_controller.py --gamification || echo "⚠️ Gamification system failed"
                      
                      if [ -f "../final_applications/gamification_dashboard.md" ]; then
                        echo "✅ Gamification system completed"
                        echo "📊 Achievements summary:"
                        grep -A 5 "## 🏆 Achievement Progress" ../final_applications/gamification_dashboard.md || echo "Achievements section not found"
                      fi
                      
              - step:
                  type: Run
                  name: Narrative Consistency Analysis
                  identifier: narrative_analysis
                  spec:
                    shell: Bash
                    command: |
                      echo "📖 Running narrative consistency analysis..."
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      echo "🔍 Analyzing document consistency and narrative flow..."
                      python3 advanced_controller.py --narrative || echo "⚠️ Narrative analysis failed"
                      
                      if [ -f "../final_applications/narrative_consistency_report.md" ]; then
                        echo "✅ Narrative analysis completed"
                        echo "📊 Consistency summary:"
                        grep -A 3 "## 📊 Overall Consistency Score" ../final_applications/narrative_consistency_report.md || echo "Consistency summary not found"
                      fi
                      
              - step:
                  type: Run
                  name: Risk Portfolio Analysis
                  identifier: portfolio_analysis
                  spec:
                    shell: Bash
                    command: |
                      echo "📊 Running risk portfolio analysis..."
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      echo "🎯 Optimizing school portfolio using financial theory..."
                      python3 advanced_controller.py --portfolio || echo "⚠️ Portfolio analysis failed"
                      
                      if [ -f "../final_applications/risk_portfolio_analysis.md" ]; then
                        echo "✅ Portfolio analysis completed"
                        echo "📊 Portfolio recommendations:"
                        grep -A 5 "## 🎯 Recommended Portfolio" ../final_applications/risk_portfolio_analysis.md || echo "Portfolio recommendations not found"
                      fi
                      
              - step:
                  type: Run
                  name: What-If Scenario Simulator
                  identifier: whatif_simulator
                  spec:
                    shell: Bash
                    command: |
                      echo "🔮 Running What-If scenario simulator..."
                      
                      cd build_scripts
                      export PYTHONPATH="${PYTHONPATH}:$(pwd)/.."
                      
                      echo "🎲 Testing strategic scenarios and optimization..."
                      python3 advanced_controller.py --whatif || echo "⚠️ What-If simulator failed"
                      
                      if [ -f "../final_applications/whatif_optimization_report.md" ]; then
                        echo "✅ What-If simulation completed"
                        echo "📊 Scenario results:"
                        grep -A 3 "## 🎯 Best Scenario" ../final_applications/whatif_optimization_report.md || echo "Scenario results not found"
                      fi

    - stage:
        name: Artifact Management and Deployment
        identifier: artifacts
        description: Save and deploy generated artifacts
        type: CI
        spec:
          cloneCodebase: true
          platform:
            os: Linux
            arch: Amd64
          runtime:
            type: Cloud
            spec: {}
          execution:
            steps:
              - step:
                  type: Run
                  name: Organize Generated Files
                  identifier: organize_files
                  spec:
                    shell: Bash
                    command: |
                      echo "📁 Organizing generated artifacts..."
                      
                      # Create artifacts directory
                      mkdir -p artifacts/reports artifacts/documents artifacts/data
                      
                      # Copy reports
                      if [ -f "final_applications/validation_report.md" ]; then
                        cp final_applications/validation_report.md artifacts/reports/
                        echo "✅ Validation report archived"
                      fi
                      
                      if [ -f "final_applications/application_dashboard.md" ]; then
                        cp final_applications/application_dashboard.md artifacts/reports/
                        echo "✅ Dashboard archived"
                      fi
                      
                      if [ -f "final_applications/academic_intelligence_report.md" ]; then
                        cp final_applications/academic_intelligence_report.md artifacts/reports/
                        echo "✅ Academic intelligence report archived"
                      fi
                      
                      if [ -f "final_applications/execution_report.md" ]; then
                        cp final_applications/execution_report.md artifacts/reports/
                        echo "✅ Execution report archived"
                      fi
                      
                      # Archive advanced features reports
                      if [ -f "final_applications/gamification_dashboard.md" ]; then
                        cp final_applications/gamification_dashboard.md artifacts/reports/
                        echo "✅ Gamification dashboard archived"
                      fi
                      
                      if [ -f "final_applications/narrative_consistency_report.md" ]; then
                        cp final_applications/narrative_consistency_report.md artifacts/reports/
                        echo "✅ Narrative analysis report archived"
                      fi
                      
                      if [ -f "final_applications/risk_portfolio_analysis.md" ]; then
                        cp final_applications/risk_portfolio_analysis.md artifacts/reports/
                        echo "✅ Portfolio analysis report archived"
                      fi
                      
                      if [ -f "final_applications/whatif_optimization_report.md" ]; then
                        cp final_applications/whatif_optimization_report.md artifacts/reports/
                        echo "✅ What-If simulation report archived"
                      fi
                      
                      # Copy structured data
                      if [ -f "final_applications/validation_results.json" ]; then
                        cp final_applications/validation_results.json artifacts/data/
                      fi
                      
                      if [ -f "final_applications/academic_intelligence.json" ]; then
                        cp final_applications/academic_intelligence.json artifacts/data/
                      fi
                      
                      # Copy application documents
                      find final_applications -name "*.md" -path "*/CV_*" -o -name "*.md" -path "*/SOP_*" | while read file; do
                        if [ -f "$file" ]; then
                          cp "$file" artifacts/documents/
                        fi
                      done
                      
                      # Create manifest
                      cat > artifacts/MANIFEST.txt << EOF
                      University Application Intelligence System v2.0
                      Generated: $(date)
                      Commit: $(git rev-parse --short HEAD)
                      Branch: $(git rev-parse --abbrev-ref HEAD)
                      Pipeline ID: <+pipeline.sequenceId>
                      
                      Files Generated:
                      EOF
                      
                      find artifacts -type f | sort >> artifacts/MANIFEST.txt
                      
                      echo "📊 Artifact Summary:"
                      echo "  Reports: $(ls artifacts/reports/*.md 2>/dev/null | wc -l)"
                      echo "  Documents: $(ls artifacts/documents/*.md 2>/dev/null | wc -l)"
                      echo "  Data Files: $(ls artifacts/data/*.json 2>/dev/null | wc -l)"
                      
              - step:
                  type: SaveCacheS3
                  name: Archive Artifacts
                  identifier: save_artifacts
                  spec:
                    connectorRef: aws_connector
                    region: us-east-1
                    bucket: university-application-artifacts
                    key: intelligence-system/<+pipeline.sequenceId>-<+codebase.commitSha>
                    sourcePaths:
                      - artifacts/
                    archiveFormat: Tar
                  when:
                    stageStatus: Success
                  failureStrategies:
                    - onFailure:
                        errors:
                          - AllErrors
                        action:
                          type: Ignore

  # Enhanced trigger configuration
  triggers:
    - trigger:
        name: Scheduled Every 3 Days Intelligence Run
        identifier: tri_daily_intelligence
        enabled: true
        description: Automated intelligence gathering and analysis every 3 days
        type: Cron
        spec:
          type: Cron
          spec:
            expression: "0 6 */3 * *"  # 6 AM UTC every 3 days
            inputYaml: |
              pipeline_mode: "full"
              skip_scraping: false
              run_advanced_features: true

    - trigger:
        name: Advanced Features Only
        identifier: advanced_only
        enabled: true
        description: Run only advanced intelligence features
        type: Manual
        spec:
          inputYaml: |
            pipeline_mode: "advanced_only"
            skip_scraping: true

    - trigger:
        name: Main Branch Push
        identifier: main_push
        enabled: true
        description: Trigger when code is pushed to main branch
        type: Webhook
        spec:
          type: Github
          spec:
            type: Push
            spec:
              connectorRef: github_connector
              autoAbortPreviousExecutions: false
              payloadConditions:
                - key: targetBranch
                  operator: Equals
                  value: main
              headerConditions: []
            inputYaml: |
              pipeline_mode: "full"
              skip_scraping: false
              run_advanced_features: true

    - trigger:
        name: Main Branch Pull Request
        identifier: main_pr
        enabled: true
        description: Trigger when PR is opened/updated to main branch
        type: Webhook
        spec:
          type: Github
          spec:
            type: PullRequest
            spec:
              connectorRef: github_connector
              autoAbortPreviousExecutions: false
              payloadConditions:
                - key: targetBranch
                  operator: Equals
                  value: main
              headerConditions: []
              actions:
                - opened
                - synchronize
                - reopened
            inputYaml: |
              pipeline_mode: "quick"
              skip_scraping: true
              run_advanced_features: false

    - trigger:
        name: Source Data Changes
        identifier: source_data_changes
        enabled: true
        description: Trigger when source data is modified
        type: Webhook
        spec:
          type: Github
          spec:
            type: PullRequest
            spec:
              connectorRef: github_connector
              autoAbortPreviousExecutions: false
              payloadConditions:
                - key: changedFiles
                  operator: Contains
                  value: source_data/
              headerConditions: []
              actions:
                - opened
                - synchronize
                - reopened
            inputYaml: |
              pipeline_mode: "quick"
              skip_scraping: true

    - trigger:
        name: Template Updates
        identifier: template_updates
        enabled: true
        description: Trigger when templates are modified
        type: Webhook
        spec:
          type: Github
          spec:
            type: Push
            spec:
              connectorRef: github_connector
              autoAbortPreviousExecutions: false
              payloadConditions:
                - key: changedFiles
                  operator: Contains
                  value: templates/
              headerConditions: []
            inputYaml: |
              pipeline_mode: "docs_only"

    - trigger:
        name: Manual Full Pipeline
        identifier: manual_full
        enabled: true
        description: Manual trigger for complete intelligence pipeline
        type: Manual
        spec:
          inputYaml: |
            pipeline_mode: "full"
            skip_scraping: false

  # Pipeline variables
  variables:
    - name: pipeline_mode
      type: String
      description: Pipeline execution mode (full, quick, docs_only, advanced_only)
      value: "quick"
    - name: skip_scraping
      type: String
      description: Skip web scraping to speed up execution
      value: "true"
    - name: target_schools
      type: String
      description: Specific schools to process (comma-separated)
      value: ""
    - name: notification_level
      type: String
      description: Notification verbosity level
      value: "normal"
    - name: run_advanced_features
      type: String
      description: Run advanced AI-powered features (gamification, narrative, portfolio, whatif)
      value: "true"
    - name: advanced_features_timeout
      type: String
      description: Timeout for advanced features in seconds
      value: "300"

  # Enhanced notification rules
  notificationRules:
    - name: Pipeline Success Notification
      identifier: success_notification
      pipelineEvents:
        - type: PipelineSuccess
      notificationMethod:
        type: Email
        spec:
          userGroups: []
          recipients:
            - admin@dennisleehappy.org
          subject: "✅ Application Intelligence Pipeline Completed Successfully"
          body: |
            The University Application Intelligence System pipeline has completed successfully.
            
            Pipeline ID: <+pipeline.sequenceId>
            Execution Time: <+pipeline.startTs>
            Commit: <+codebase.commitSha>
            
            Generated artifacts are available in the S3 bucket.
            
            Best regards,
            Application Intelligence System
      enabled: true
    
    - name: Pipeline Failure Notification
      identifier: failure_notification
      pipelineEvents:
        - type: PipelineFailed
      notificationMethod:
        type: Email
        spec:
          userGroups: []
          recipients:
            - admin@dennisleehappy.org
          subject: "❌ Application Intelligence Pipeline Failed"
          body: |
            The University Application Intelligence System pipeline has failed.
            
            Pipeline ID: <+pipeline.sequenceId>
            Failed Stage: <+pipeline.stage.name>
            Error Details: <+pipeline.stage.spec.execution.steps.step.failureStrategies>
            
            Please check the pipeline logs for detailed error information.
            
            Best regards,
            Application Intelligence System
      enabled: true

    - name: High Priority Alerts
      identifier: high_priority_alerts
      pipelineEvents:
        - type: PipelineSuccess
      notificationMethod:
        type: Slack
        spec:
          webhookUrl: <+secrets.getValue("slack_webhook_url")>
          message: |
            🎓 *Application Intelligence Update*
            
            Pipeline completed with new high-priority alerts detected.
            Check GitHub Issues for action items.
            
            Pipeline: <+pipeline.sequenceId>
      enabled: false  # Enable when Slack webhook is configured
      conditions:
        - key: pipeline.variables.high_priority_alerts
          operator: Equals
          value: "true"
